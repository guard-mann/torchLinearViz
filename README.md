# torchLinearViz
Rleased torchLinearViz on https://pypi.org/project/torchLinearViz/

This is a tool to draw Neural Network architecture designed by PyTorch by Unit level especially in Linear layer. (other layers are drawn through layer-level like following figure.)

![demo image](./image/overview.png)


# How to install
```
pip install torchLinearViz
```

# Generated file
`epoch_visualizer.html` file is generated. In this file you can operate as the gif below.

![demo of html file usage](./movie/manual.gif)

- You can change view by "Switch Data" button (`Value` means value of weight, `Diff` means difference between last epoch)
- By "Start Video" button, you can see animation across epoch, this can zoom up or change position and position of node as you like.
- You can change Speed
- You can change Scale of each weight (if you set max as 1, min as 0 when `Diff` case, you will see nothing to change across epochs, but set "max" as 0.01, then you will see the change of weight clearly.)
- You can set Colorscheme (light or dark)

# demo Code
 Following code is from `./tests/demoMNIST.py` of this repo. Inserting "Initializer", "Update", "Save" lines, this library works, and `epoch_visualizer.html` will be generated.

```
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

# here import torchLinearViz
from torchLinearViz import TorchLinearViz

# ğŸ”¹ 1. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])

# ğŸ”¹ 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)

# ğŸ”¹ 3. MLPï¼ˆå…¨çµåˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.model = nn.Sequential(
            nn.Flatten(),  # ç”»åƒ(28x28) â†’ 1æ¬¡å…ƒ (784)
            nn.Linear(28*28, 5),  # å…¥åŠ› 784 â†’ éš ã‚Œå±¤ 256 
#            nn.ReLU(),
            nn.Linear(5, 5),  # éš ã‚Œå±¤ 256 â†’ 128
#            nn.ReLU(),
            nn.Linear(5, 10)  # å‡ºåŠ› 10ã‚¯ãƒ©ã‚¹
        )

    def forward(self, x):
        return self.model(x)

# ğŸ”¹ 4. ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = MLP().to(device)

# ğŸ”¹ 5. æå¤±é–¢æ•°ã¨æœ€é©åŒ–æ‰‹æ³•
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# torchLinearViz initialize
torchlinearviz = TorchLinearViz(model)

# ğŸ”¹ 6. å­¦ç¿’
epochs = 100
for epoch in range(epochs):
    model.train()
    total_loss = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    # here updates weights of model
    torchlinearviz.update(model, images)

    print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}")

# here generates html file
torchlinearviz.end()
```
